{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d228305-eb2e-4771-93fd-44a6815ad240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seisbench\n",
    "import seisbench.data as sbd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3706971-48a2-43f1-96f8-ddbbe7724472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LenDB - 1244942 traces\n"
     ]
    }
   ],
   "source": [
    "data = sbd.LenDB()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5715a0f-23f1-4d3a-b60e-5669de64efe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629095\n"
     ]
    }
   ],
   "source": [
    "rows_earthquake = data.metadata[data.metadata[\"trace_category\"] == \"earthquake\"]\n",
    "print(len(rows_earthquake.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf071256-fd28-4c12-a995-013f45df343e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615847\n"
     ]
    }
   ],
   "source": [
    "rows_noise = data.metadata[data.metadata[\"trace_category\"] == \"noise\"]\n",
    "print(len(rows_noise.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7b8992d-6e72-4afd-b231-5ba8e28dd963",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 100000\n",
    "rnd_earthquake = np.random.choice(rows_earthquake.index, size, replace=False)\n",
    "rnd_noise = np.random.choice(rows_noise.index, size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f73b44f-5b8f-4157-af18-7f9dfb51e282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earthquake dataset shape: (100000, 3, 540)\n"
     ]
    }
   ],
   "source": [
    "dataset_e = data.get_waveforms(rnd_earthquake)\n",
    "print(\"Earthquake dataset shape:\", dataset_e.shape)\n",
    "label_e = np.ones(size)\n",
    "#print(label_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f97dfe40-70dc-437a-9b5e-fe352d4dd207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise dataset shape: (100000, 3, 540)\n"
     ]
    }
   ],
   "source": [
    "dataset_n = data.get_waveforms(rnd_noise)\n",
    "print(\"Noise dataset shape:\", dataset_n.shape)\n",
    "label_n = np.zeros(size)\n",
    "#print(label_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e1029-665f-4055-83ed-16ab465fce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtx = np.concatenate((dataset_e, dataset_n), axis=0)\n",
    "Y = np.concatenate((label_e, label_n), axis=0)\n",
    "# Shuffling\n",
    "random_indexes = np.arange(Y.shape[0])\n",
    "np.random.shuffle(random_indexes)\n",
    "mtx = mtx[random_indexes]\n",
    "Y = Y[random_indexes]\n",
    "\n",
    "print(\"data.shape:\", mtx.shape)\n",
    "print(\"label.shape:\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684957d1-cde3-45d6-8cd6-f89a9df6972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_mean = np.mean(X, axis=0, keepdims=True)\n",
    "# print(overall_mean.shape)\n",
    "# Xnorm = X - overall_mean\n",
    "# print(X.shape)\n",
    "# # print(Xnorm.min())\n",
    "# # print(Xnorm.max())\n",
    "# # print(Xnorm)\n",
    "# ov_std = X.std(axis=0, keepdims=True)\n",
    "# print(ov_std.shape)\n",
    "# X = Xnorm/ov_std\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d4d1c-cc3d-44c8-af9f-6b977460cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnorm = (mtx - mtx.mean(axis =0, keepdims=True) )/ (mtx.std(axis=0, keepdims=True))\n",
    "# print(X.shape)\n",
    "# print(Xnorm)\n",
    "# print(Xnorm.min())\n",
    "# print(Xnorm.max())\n",
    "print(Xnorm.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f32232-c0ff-4c1d-a4a0-2e8eb2b34918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras want the channel last so we have to tranpose on the dimension that we want \n",
    "X = np.transpose(Xnorm, axes = (0,2,1))\n",
    "print(X.std(axis=0))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e66cc90-3779-4d03-ad16-1a5ea0a04dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_temp, X_temp, y_train_temp, y_temp = train_test_split(X , Y, test_size=0.2)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp , y_temp, test_size=0.2)\n",
    "\n",
    "print(\"Train:\", X_train_temp.shape)\n",
    "#print(\"Train labels\", y_train_temp.mean())\n",
    "print(\"Label Train:\", y_train_temp.shape)\n",
    "print(\"Valid:\", X_val.shape)\n",
    "print(\"Label valid:\", y_val.shape)\n",
    "print(\"Test:\", X_test.shape)\n",
    "print(\"Label Test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75449c6a-23ef-4d72-b07c-312ae9d14930",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    \n",
    "    # Convolution 1\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=3, strides=2, activation=\"relu\", input_shape=(540,3)),\n",
    "    # output( 64, 269)\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # Convolution 2\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=3, strides=2, activation=\"relu\"),\n",
    "    # output( 64, 134)\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # Convolution 3\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=3, strides=2, activation=\"relu\"),\n",
    "    # output( 64, 66)\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # Convolution 4\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=3, strides=2, activation=\"relu\"),\n",
    "    # output( 64, 32)\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # Convolution 5\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=3, strides=2, activation=\"relu\"),\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation=\"relu\"),\n",
    "    # keras.layers.Dropout(0.5),\n",
    "    # keras.layers.Dense(5, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6783bce-f8c8-4a4b-a4e1-057c56b4a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_temp.std(axis=0)\n",
    "print(np.abs(X_train_temp).min())\n",
    "print(np.abs(X_train_temp).max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac060ac3-8b02-4db4-898b-fd6638dadc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.build((None, n_timesteps, n_features, n_outputs))\n",
    "\n",
    "model.build()\n",
    "# Check that your model looks right\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88710866-38ea-4104-8ea6-bb75b8366549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import BinaryCrossentropy\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# adam_opt = Adam(learning_rate=1e-5)\n",
    "logits_loss = BinaryCrossentropy(\n",
    "     from_logits=True)\n",
    "\n",
    "model.compile(loss=logits_loss, optimizer=adam_opt, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b8bb2-5bf8-4901-a258-310a94b08d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_temp, y_train_temp, epochs=100, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e8f77f-64ac-4715-9ec4-ac9eb3ec2cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171a6282-7f37-45af-b82d-2f55b351ec38",
   "metadata": {},
   "source": [
    "I need a baseline for the final project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seisbench2_venv",
   "language": "python",
   "name": "seisbench2_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
